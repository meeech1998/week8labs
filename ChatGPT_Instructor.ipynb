{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83fab2fc-3d34-4138-b1d1-075a785933d2",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e16930-fb6f-4c50-8fb4-f7636b3919c0",
   "metadata": {},
   "source": [
    "Hi ChatGPT, Iâ€™m working on my Week 8 Instructor-led Lab for my graduate Python course (BGEN 632 - UM MSBA). \n",
    "I am not looking for final answers. I want help understanding how to approach the assignment step-by-step. Provde a step by Step using a different hypothetical question without giving me answers so I can figute it out myself.\n",
    "Can you walk me through how I should structure the logic using pseudo-code or examplesâ€”without giving me the full solution? Iâ€™ll write my own code based on what I learn. # Instructor-led Lab: Advanced Data Manipulation\n",
    "\n",
    "In this assignment you will practice your new skills in data manipulation with the *piping* expression for `pandas`. Please follow the instructions below.\n",
    "\n",
    "## Sorting and Ordering Data\n",
    "\n",
    "Last week you sorted, ordered, and filtered the data [github_teams.csv](/data/github_teams.csv) using basic pandas techniques. Now that you have learned to use advanced techniques relying on piping expressions, you will perform the similar operations again, but with your new skills. \n",
    "\n",
    "Please perform the following operations in order:\n",
    "\n",
    "* Select the columns `Team_type`, `human_work`, and `work_per_human`.\n",
    "* Select columns that end in the letter `t`. Use the regex `t$`.\n",
    "* Sort your data descending using the columns `Team_size_class`, `human_work`, `work_per_human`.\n",
    "* Select `human-bot` teams that have a `bot_members_count` value greater than and equal to 3.\n",
    "* Find the `human` teams that are `Large` and have a `human_gini` value greater than and equal to 0.75.\n",
    "* How many teams are in the `Small` or `Large` category?\n",
    "* How many teams are in the `Small` or `Large` category with a `human_gini` value less than and equal to 0.25?\n",
    "* How many `human` teams are in the `Medium` category?\n",
    "* Save the columns `Team_size_class` and `work_per_human` as a new DataFrame.\n",
    "* Rename these two columns in the new DataFrame. Change `human_gini` to `work_inequality` and `eval_survival_day_median` to `issue_resolution_time`.\n",
    "\n",
    "## Dataset Contents\n",
    "\n",
    "| Variable  | Description | \n",
    "| :------------ |:---------------|\n",
    "| name_h | Alphanumeric hash generated to anonymize repo name |\n",
    "| Team_type |  A qualitative descriptor indicating whether the team was made of only humans or a blend of humans and bots (two levels: human, human-bot) |\n",
    "| Team_size_class |  A qualitative descriptor indicating the size of the team, derived from human_members_count (three levels: small [2, 3], medium [4, 6], large [7, 246]) |\n",
    "| human_members_count  | The number of human users in the repo |\n",
    "| bot_members_count | The number of bots in the repo |\n",
    "| human_work | The number of work events generated by humans in the repo |\n",
    "| work_per_human | The ratio of works events to humans, derived from human_members_count and human_work |\n",
    "| human_gini | Gini coefficient for human work in the repo |\n",
    "| human_Push | The number of push events generated by humans in the repo |\n",
    "| human_IssueComments | The number of issue comment events generated by humans in the repo |\n",
    "| human_PRReviewComment | The number of pull request review comment events generated by humans in the repo |\n",
    "| human_MergedPR | The number of merged pull request events generated by humans in the repo |\n",
    "| bot_work | The number of work events generated by bots in the repo |\n",
    "| bot_Push | The number of push events generated by bots in the repo |\n",
    "| bot_IssueComments | The number of issue comment events generated by bots in the repo |\n",
    "| bot_PRReviewComment | The number of pull request review comment events generated by bots in the repo |\n",
    "| bot_MergedPR | The number of merged pull request events generated by bots in the repo |\n",
    "| eval_survival_day_median | The median number of days that an issue remained open in the repo (teams who were not included in issue survival analysis have NA value) |\n",
    "| issues_count | The number of issues in the repo |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b90f97b-d48a-45a5-ad0d-9ffc26dca658",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b49c14f-0a4f-491a-98f0-87be5b0ce8e7",
   "metadata": {},
   "source": [
    "Absolutely, Michelle. I love how youâ€™re trying to understand the logic rather than just plugging in answersâ€”letâ€™s walk through how to approach this lab like a pro using a parallel, hypothetical example that mirrors each of the tasks from your GitHub teams lab.\n",
    "\n",
    "â¸»\n",
    "\n",
    "ðŸ”§ Setup (Hypothetical Data)\n",
    "\n",
    "Letâ€™s say youâ€™re working with a dataset called project_teams.csv with columns like:\n",
    "\tâ€¢\tProject_type: â€œinternalâ€, â€œexternalâ€\n",
    "\tâ€¢\tHours_logged: total hours logged by humans\n",
    "\tâ€¢\thours_per_person: ratio of hours per person\n",
    "\tâ€¢\tTeam_size_category: â€œSmallâ€, â€œMediumâ€, â€œLargeâ€\n",
    "\tâ€¢\tai_members_count: number of AI agents\n",
    "\tâ€¢\thuman_diversity: Gini coefficient (like human_gini)\n",
    "\tâ€¢\tresolution_days_median: median time to resolve issues\n",
    "\n",
    "â¸»\n",
    "\n",
    "ðŸ§  Step-by-Step Pseudo-Logic with Parallel Thinking\n",
    "\n",
    "â¸»\n",
    "\n",
    "ðŸ”¹ Task 1: Select Specific Columns\n",
    "\n",
    "ðŸ§© How do I pull out only the few columns I want to analyze?\n",
    "\n",
    "Pseudocode:\n",
    "\n",
    "(df\n",
    " .filter([\"Project_type\", \"Hours_logged\", \"hours_per_person\"])\n",
    ")\n",
    "\n",
    "Think: â€œUse .filter([...]) to extract columns just like select() in R.â€\n",
    "\n",
    "â¸»\n",
    "\n",
    "ðŸ”¹ Task 2: Select Columns That End in â€˜tâ€™\n",
    "\n",
    "ðŸ§© What if I want columns with names ending in a certain character?\n",
    "\n",
    "Pseudocode:\n",
    "\n",
    "(df\n",
    " .filter(regex=\"t$\")\n",
    ")\n",
    "\n",
    "Think: Use regular expressions with .filter(regex=\"pattern\") to dynamically select columns.\n",
    "\n",
    "â¸»\n",
    "\n",
    "ðŸ”¹ Task 3: Sort Data Descending by Multiple Columns\n",
    "\n",
    "ðŸ§© How do I sort based on multiple fields, in reverse order?\n",
    "\n",
    "Pseudocode:\n",
    "\n",
    "(df\n",
    " .sort_values(by=[\"Team_size_category\", \"Hours_logged\", \"hours_per_person\"], ascending=False)\n",
    ")\n",
    "\n",
    "Think: .sort_values() lets you order the rows. The list of column names tells pandas how to sort.\n",
    "\n",
    "â¸»\n",
    "\n",
    "ðŸ”¹ Task 4: Filter by Two Conditions\n",
    "\n",
    "ðŸ§© How do I find all external projects with â‰¥ 3 AI members?\n",
    "\n",
    "Pseudocode:\n",
    "\n",
    "(df\n",
    " .query(\"Project_type == 'external' and ai_members_count >= 3\")\n",
    ")\n",
    "\n",
    "Think: .query() is like SQL WHERE. Combine multiple filters with and or or.\n",
    "\n",
    "â¸»\n",
    "\n",
    "ðŸ”¹ Task 5: Filter by Categorical and Numeric Condition\n",
    "\n",
    "ðŸ§© How do I get internal, large teams with high diversity inequality?\n",
    "\n",
    "Pseudocode:\n",
    "\n",
    "(df\n",
    " .query(\"Project_type == 'internal' and Team_size_category == 'Large' and human_diversity >= 0.75\")\n",
    ")\n",
    "\n",
    "Think: You can use strings for categories and numeric comparisons in one expression.\n",
    "\n",
    "â¸»\n",
    "\n",
    "ðŸ”¹ Task 6: Count Rows for Multiple Categories\n",
    "\n",
    "ðŸ§© How many projects are Small or Large?\n",
    "\n",
    "Pseudocode:\n",
    "\n",
    "(df\n",
    " .query(\"Team_size_category in ['Small', 'Large']\")\n",
    " .shape[0]\n",
    ")\n",
    "\n",
    "Think: .shape[0] gives you the number of rows (i.e., teams) after filtering.\n",
    "\n",
    "â¸»\n",
    "\n",
    "ðŸ”¹ Task 7: Add Extra Condition on Numeric Column\n",
    "\n",
    "ðŸ§© Now only count if those same teams have low diversity.\n",
    "\n",
    "Pseudocode:\n",
    "\n",
    "(df\n",
    " .query(\"Team_size_category in ['Small', 'Large'] and human_diversity <= 0.25\")\n",
    " .shape[0]\n",
    ")\n",
    "\n",
    "Think: Add an additional filter to the same .query() chain.\n",
    "\n",
    "â¸»\n",
    "\n",
    "ðŸ”¹ Task 8: Count Based on Category + Another Condition\n",
    "\n",
    "ðŸ§© How many internal, medium teams exist?\n",
    "\n",
    "Pseudocode:\n",
    "\n",
    "(df\n",
    " .query(\"Project_type == 'internal' and Team_size_category == 'Medium'\")\n",
    " .shape[0]\n",
    ")\n",
    "\n",
    "Think: Filter down by combining values across two columns.\n",
    "\n",
    "â¸»\n",
    "\n",
    "ðŸ”¹ Task 9: Create New DataFrame With Selected Columns\n",
    "\n",
    "ðŸ§© I want to reuse only size and hours-per-person for new analysis.\n",
    "\n",
    "Pseudocode:\n",
    "\n",
    "new_df = df.filter([\"Team_size_category\", \"hours_per_person\"])\n",
    "\n",
    "Think: Save a slimmed-down version of the dataset to a new variable.\n",
    "\n",
    "â¸»\n",
    "\n",
    "ðŸ”¹ Task 10: Rename Columns\n",
    "\n",
    "ðŸ§© How do I rename columns for better reporting/plotting?\n",
    "\n",
    "Pseudocode:\n",
    "\n",
    "renamed_df = (new_df\n",
    "              .rename(columns={\n",
    "                  \"hours_per_person\": \"efficiency_score\"\n",
    "              }))\n",
    "\n",
    "Think: Use a dictionary inside .rename(columns={...}) to swap old â†’ new names.\n",
    "\n",
    "If youâ€™re renaming from the full dataset:\n",
    "\n",
    "renamed_df = (df\n",
    "              .filter([\"Team_size_category\", \"hours_per_person\", \"resolution_days_median\"])\n",
    "              .rename(columns={\n",
    "                  \"hours_per_person\": \"efficiency_score\",\n",
    "                  \"resolution_days_median\": \"issue_resolution_time\"\n",
    "              }))\n",
    "\n",
    "\n",
    "\n",
    "â¸»\n",
    "\n",
    "ðŸ§° Final Advice\n",
    "\n",
    "To implement this:\n",
    "\t1.\tUse .filter() for columns and .query() for rows.\n",
    "\t2.\tUse parentheses for piping across multiple method calls.\n",
    "\t3.\tTest one line at a time before chaining more logic.\n",
    "\t4.\tComment your code so you remember what each block does.\n",
    "\t5.\tValidate your assumptions by using .head(), .info(), and .shape.\n",
    "\n",
    "â¸»\n",
    "\n",
    "Would you like me to review your pseudocode before you test it on github_teams.csv?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
