{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a78b4ba-18f1-450a-bfc2-7fe89a7547ef",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11a67ff-da65-40a6-b06b-f53282400c4c",
   "metadata": {},
   "source": [
    "Hi ChatGPT, I’m working on my Week 8 Instructor-led Lab for my graduate Python course (BGEN 632 - UM MSBA). \n",
    "I am not looking for final answers. I want help understanding how to approach the assignment step-by-step. Provde a step by Step using a different hypothetical question without giving me answers so I can figute it out myself.\n",
    "Can you walk me through how I should structure the logic using pseudo-code or examples—without giving me the full solution? I’ll write my own code based on what I learn. # Instructor-led Lab: Advanced Data Manipulation\n",
    "\n",
    "In this assignment you will practice your new skills in data manipulation with the *piping* expression for `pandas`. Please follow the instructions below.\n",
    "\n",
    "## Sorting and Ordering Data\n",
    "\n",
    "Last week you sorted, ordered, and filtered the data [github_teams.csv](/data/github_teams.csv) using basic pandas techniques. Now that you have learned to use advanced techniques relying on piping expressions, you will perform the similar operations again, but with your new skills. \n",
    "\n",
    "Please perform the following operations in order:\n",
    "\n",
    "* Select the columns `Team_type`, `human_work`, and `work_per_human`.\n",
    "* Select columns that end in the letter `t`. Use the regex `t$`.\n",
    "* Sort your data descending using the columns `Team_size_class`, `human_work`, `work_per_human`.\n",
    "* Select `human-bot` teams that have a `bot_members_count` value greater than and equal to 3.\n",
    "* Find the `human` teams that are `Large` and have a `human_gini` value greater than and equal to 0.75.\n",
    "* How many teams are in the `Small` or `Large` category?\n",
    "* How many teams are in the `Small` or `Large` category with a `human_gini` value less than and equal to 0.25?\n",
    "* How many `human` teams are in the `Medium` category?\n",
    "* Save the columns `Team_size_class` and `work_per_human` as a new DataFrame.\n",
    "* Rename these two columns in the new DataFrame. Change `human_gini` to `work_inequality` and `eval_survival_day_median` to `issue_resolution_time`.\n",
    "\n",
    "## Dataset Contents\n",
    "\n",
    "| Variable  | Description | \n",
    "| :------------ |:---------------|\n",
    "| name_h | Alphanumeric hash generated to anonymize repo name |\n",
    "| Team_type |  A qualitative descriptor indicating whether the team was made of only humans or a blend of humans and bots (two levels: human, human-bot) |\n",
    "| Team_size_class |  A qualitative descriptor indicating the size of the team, derived from human_members_count (three levels: small [2, 3], medium [4, 6], large [7, 246]) |\n",
    "| human_members_count  | The number of human users in the repo |\n",
    "| bot_members_count | The number of bots in the repo |\n",
    "| human_work | The number of work events generated by humans in the repo |\n",
    "| work_per_human | The ratio of works events to humans, derived from human_members_count and human_work |\n",
    "| human_gini | Gini coefficient for human work in the repo |\n",
    "| human_Push | The number of push events generated by humans in the repo |\n",
    "| human_IssueComments | The number of issue comment events generated by humans in the repo |\n",
    "| human_PRReviewComment | The number of pull request review comment events generated by humans in the repo |\n",
    "| human_MergedPR | The number of merged pull request events generated by humans in the repo |\n",
    "| bot_work | The number of work events generated by bots in the repo |\n",
    "| bot_Push | The number of push events generated by bots in the repo |\n",
    "| bot_IssueComments | The number of issue comment events generated by bots in the repo |\n",
    "| bot_PRReviewComment | The number of pull request review comment events generated by bots in the repo |\n",
    "| bot_MergedPR | The number of merged pull request events generated by bots in the repo |\n",
    "| eval_survival_day_median | The median number of days that an issue remained open in the repo (teams who were not included in issue survival analysis have NA value) |\n",
    "| issues_count | The number of issues in the repo |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f670479-a0d7-4927-8eae-958bee5dc044",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97075eab-cc8b-4ad8-8849-f476f4e05603",
   "metadata": {},
   "source": [
    "Absolutely, Michelle! Here’s a step-by-step walk-through using pseudo-code and a different hypothetical example, so you can confidently apply the same logic to your GitHub teams lab.\n",
    "\n",
    "⸻\n",
    "\n",
    "🧠 Hypothetical Scenario (Just for Practice)\n",
    "\n",
    "Imagine you have a dataset: startup_teams.csv, with the following columns:\n",
    "\t•\tTeam_category = type of team (human-only, human-ai)\n",
    "\t•\tTeam_size = size category (Small, Medium, Large)\n",
    "\t•\tai_members = number of AI agents\n",
    "\t•\thuman_effort = number of work units by humans\n",
    "\t•\teffort_per_human = human_effort divided by human headcount\n",
    "\t•\teffort_gini = Gini coefficient for effort distribution\n",
    "\t•\tresolution_days_median = median time to resolve tasks\n",
    "\n",
    "⸻\n",
    "\n",
    "✅ Pseudo-Code Strategy by Task (Matches Your Real Assignment)\n",
    "\n",
    "⸻\n",
    "\n",
    "1. Select specific columns\n",
    "\n",
    "Goal: Select \"Team_category\", \"human_effort\", \"effort_per_human\"\n",
    "\n",
    "# Think: df %>% select(...)\n",
    "(df\n",
    " .filter([\"Team_category\", \"human_effort\", \"effort_per_human\"])\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "⸻\n",
    "\n",
    "2. Select columns ending in “t” using regex\n",
    "\n",
    "Goal: Keep only columns like effort_per_human, result_count, etc.\n",
    "\n",
    "(df\n",
    " .filter(regex=\"t$\")\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "⸻\n",
    "\n",
    "3. Sort by multiple columns descending\n",
    "\n",
    "Goal: Sort by Team_size, human_effort, effort_per_human\n",
    "\n",
    "(df\n",
    " .sort_values(by=[\"Team_size\", \"human_effort\", \"effort_per_human\"], ascending=False)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "⸻\n",
    "\n",
    "4. Filter rows with two conditions\n",
    "\n",
    "Goal: Only human-ai teams with ≥ 3 AI members\n",
    "\n",
    "(df\n",
    " .query(\"Team_category == 'human-ai' and ai_members >= 3\")\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "⸻\n",
    "\n",
    "5. Filter based on size and inequality\n",
    "\n",
    "Goal: Only large human teams with high effort Gini (≥ 0.75)\n",
    "\n",
    "(df\n",
    " .query(\"Team_category == 'human' and Team_size == 'Large' and effort_gini >= 0.75\")\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "⸻\n",
    "\n",
    "6. Count teams in Small or Large category\n",
    "\n",
    "(df\n",
    " .query(\"Team_size in ['Small', 'Large']\")\n",
    " .shape[0]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "⸻\n",
    "\n",
    "7. Count Small/Large teams with low Gini (≤ 0.25)\n",
    "\n",
    "(df\n",
    " .query(\"Team_size in ['Small', 'Large'] and effort_gini <= 0.25\")\n",
    " .shape[0]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "⸻\n",
    "\n",
    "8. Count human-only Medium teams\n",
    "\n",
    "(df\n",
    " .query(\"Team_category == 'human' and Team_size == 'Medium'\")\n",
    " .shape[0]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "⸻\n",
    "\n",
    "9. Save subset of two columns as new DataFrame\n",
    "\n",
    "new_df = df.filter([\"Team_size\", \"effort_per_human\"])\n",
    "\n",
    "\n",
    "\n",
    "⸻\n",
    "\n",
    "10. Rename columns in the new DataFrame\n",
    "\n",
    "If it had these names, this would be the logic:\n",
    "\n",
    "new_df.rename(columns={\n",
    "    \"effort_gini\": \"effort_inequality\",\n",
    "    \"resolution_days_median\": \"task_resolution_time\"\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "⸻\n",
    "\n",
    "🧭 General Tips for Your Real Lab\n",
    "\t•\tThink in terms of: Filter → Query → Sort → Save → Rename\n",
    "\t•\tUse .query() for row conditions, .filter() for column selection\n",
    "\t•\tWrap your pipelines in parentheses () for clean chaining\n",
    "\t•\tThink of each .method() as the next %>% step in tidyverse\n",
    "\n",
    "⸻\n",
    "\n",
    "Let me know when you’re ready to test your logic on the actual dataset and I can help you debug or structure your answers!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
